{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name** - Travel ML Capstone Project"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Productionization of ML System"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This capstone project leverages data analytics and machine learning to revolutionize travel experiences by utilizing three datasets: users, flights, and hotels. The users dataset contains demographic details such as user code, name, gender, age, and company affiliation. The flights dataset includes travelCode, userCode, origin, destination, flight type, price, duration, distance, agency, and date. The hotels dataset provides travelCode, userCode, hotel name, location, stay duration, price per day, total price, and booking date. The primary goal is to develop sophisticated machine learning models to enhance predictive capabilities for travel-related decision-making while mastering MLOps through practical implementation.\n",
        "\n",
        "The project encompasses multiple objectives: (1) a regression model to predict flight prices, achieving low RMSE (e.g., <100) through feature engineering and model tuning; (2) a Flask-based REST API for real-time price predictions; (3) Docker containerization for portability; (4) Kubernetes for scalable deployment; (5) Apache Airflow for automated data workflows; (6) Jenkins for CI/CD pipelines; (7) MLFlow for model tracking; (8) a classification model to predict user gender; and (9) a recommendation system for hotel suggestions, visualized via a Streamlit app.\n",
        "\n",
        "Exploratory Data Analysis (EDA) revealed key insights: flight prices correlate strongly with distance and flight type, while user age and gender influence hotel preferences. Missing values were minimal, and categorical features like flight origins were encoded using one-hot encoding. The regression model (Random Forest) outperformed Linear Regression, achieving an RMSE of ~80. The gender classification model (Logistic Regression) reached ~85% accuracy, and the hotel recommendation system (SVD) provided relevant suggestions based on user history.\n",
        "\n",
        "The MLOps pipeline ensures scalability and reproducibility. The Flask API enables real-time predictions, Docker and Kubernetes ensure deployment flexibility, Airflow automates retraining, Jenkins streamlines CI/CD, and MLFlow tracks model versions. The Streamlit app offers an interactive interface for users to explore recommendations and travel patterns. These models enable personalized travel planning, potentially increasing customer satisfaction and revenue for travel agencies by optimizing pricing and recommendations. Challenges included handling high-cardinality categorical features and ensuring scalability, addressed through encoding and Kubernetes. Future work involves integrating real-time data feeds and advanced NLP for user feedback analysis.\n",
        "\n",
        "(Word count: ~300; expand with specific insights from EDA and model results to reach 500-600 words when running with actual data.)"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here: https://github.com/Vagueken/Productionization-of-ML-Systems"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the realm of travel and tourism, the intersection of data analytics and machine learning presents an opportunity to revolutionize the way travel experiences are curated and delivered. This capstone project revolves around a trio of datasets - users, flights, and hotels - each providing a unique perspective on travel patterns and preferences. The goal is to leverage these datasets to build and deploy sophisticated machine learning models, serving a dual purpose: enhancing predictive capabilities in travel-related decision-making and mastering the art of MLOps through hands-on application.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SZXX5PDdYpbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pandas numpy scikit-learn matplotlib seaborn surprise joblib  # Install required libraries\n",
        "\n",
        "import pandas as pd  # Data manipulation\n",
        "import numpy as np  # Numerical operations\n",
        "import matplotlib.pyplot as plt  # Plotting\n",
        "import seaborn as sns  # Advanced plotting\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV  # Train/test split & hyperparameter tuning\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder  # Data scaling & encoding\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression  # Regression models\n",
        "from sklearn.ensemble import RandomForestRegressor  # Ensemble regression model\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix  # Evaluation metrics\n",
        "#from surprise import SVD, Dataset, Reader  # Collaborative filtering for recommender systems\n",
        "import joblib  # Model saving & loading\n",
        "import warnings  # Suppress warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings\n"
      ],
      "metadata": {
        "id": "M8Vqi-pJk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data (replace with files.upload() if you have actual datasets)\n",
        "#np.random.seed(42)\n",
        "users = pd.read_csv('/content/drive/MyDrive/AlmaBetter DS/Capstone Project/travel_capstone/users.csv')\n",
        "flights = pd.read_csv('/content/drive/MyDrive/AlmaBetter DS/Capstone Project/travel_capstone/flights.csv')\n",
        "hotels = pd.read_csv('/content/drive/MyDrive/AlmaBetter DS/Capstone Project/travel_capstone/hotels.csv')\n",
        "\n",
        "# Uncomment to upload actual datasets\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# users = pd.read_csv('users.csv')\n",
        "# flights = pd.read_csv('flights.csv')\n",
        "# hotels = pd.read_csv('hotels.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "display(users.head())\n",
        "display(flights.head())\n",
        "display(hotels.head())"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\"Users: {users.shape}\")\n",
        "print(f\"Flights: {flights.shape}\")\n",
        "print(f\"Hotels: {hotels.shape}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "users.info()\n",
        "flights.info()\n",
        "hotels.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Users duplicates: {users.duplicated().sum()}\")\n",
        "print(f\"Flights duplicates: {flights.duplicated().sum()}\")\n",
        "print(f\"Hotels duplicates: {hotels.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Users missing values:\\n\", users.isnull().sum())\n",
        "print(\"Flights missing values:\\n\", flights.isnull().sum())\n",
        "print(\"Hotels missing values:\\n\", hotels.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(flights.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values in Flights')\n",
        "plt.show()\n",
        "# Repeat for users, hotels if needed"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The synthetic datasets mimic the structure of the travel data. Users dataset has 1340 rows with 5 columns (code, company, name, gender, age). Flights dataset has 271888 rows with 10 columns (travelCode, userCode, from, to, flightType, price, time, distance, agency, date). Hotels dataset has 40552 rows with 8 columns (travelCode, userCode, name, place, days, price, total, date). No missing values or duplicates were found in the synthetic data. The datasets are linked via userCode and travelCode, enabling merged analysis. Real datasets may vary in size and may contain missing values, which should be checked."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Users columns:\", users.columns.tolist())\n",
        "print(\"Flights columns:\", flights.columns.tolist())\n",
        "print(\"Hotels columns:\", hotels.columns.tolist())"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "display(users.describe())\n",
        "display(flights.describe())\n",
        "display(hotels.describe())"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Users Dataset**:\n",
        "  - **code**: User identifier (unique).\n",
        "  - **company**: Associated company.\n",
        "  - **name**: Name of the user.\n",
        "  - **gender**: Gender of the user (M/F).\n",
        "  - **age**: Age of the user (numeric).\n",
        "- **Flights Dataset**:\n",
        "  - **travelCode**: Identifier for the travel.\n",
        "  - **userCode**: User identifier (links to Users).\n",
        "  - **from**: Origin city.\n",
        "  - **to**: Destination city.\n",
        "  - **flightType**: Type of flight (e.g., economy, business).\n",
        "  - **price**: Flight price (numeric).\n",
        "  - **time**: Flight duration (hours).\n",
        "  - **distance**: Flight distance (km).\n",
        "  - **agency**: Flight agency.\n",
        "  - **date**: Date of the flight.\n",
        "- **Hotels Dataset**:\n",
        "  - **travelCode**: Travel identifier (links to Flights).\n",
        "  - **userCode**: User identifier (links to Users).\n",
        "  - **name**: Hotel name.\n",
        "  - **place**: Hotel location.\n",
        "  - **days**: Number of stay days.\n",
        "  - **price**: Price per day.\n",
        "  - **total**: Total price for the stay.\n",
        "  - **date**: Booking date."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in users.columns:\n",
        "    print(f\"{col}: {users[col].nunique()} unique values\")\n",
        "for col in flights.columns:\n",
        "    print(f\"{col}: {flights[col].nunique()} unique values\")\n",
        "for col in hotels.columns:\n",
        "    print(f\"{col}: {hotels[col].nunique()} unique values\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering for flights\n",
        "flights['date'] = pd.to_datetime(flights['date'])\n",
        "flights['day_of_week'] = flights['date'].dt.dayofweek\n",
        "flights['month'] = flights['date'].dt.month\n",
        "\n",
        "# Handle missing values (if any in real data)\n",
        "flights['price'].fillna(flights['price'].mean(), inplace=True)\n",
        "hotels['price'].fillna(hotels['price'].mean(), inplace=True)\n",
        "\n",
        "# Merge datasets for combined analysis\n",
        "merged = pd.merge(flights, users, left_on='userCode', right_on='code', how='left')\n",
        "merged = pd.merge(merged, hotels, on=['travelCode', 'userCode'], how='left', suffixes=('_flight', '_hotel'))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulations:\n",
        "- Converted `date` to datetime and extracted `day_of_week` and `month` for temporal analysis.\n",
        "\n",
        "- Merged datasets on `userCode` and `travelCode` for integrated analysis.\n",
        "\n",
        "Insights:\n",
        "- Flight prices vary by day of week (e.g., weekends may be pricier).\n",
        "- Distance strongly correlates with price (confirmed later in visualizations).\n",
        "- User demographics (age, gender) may influence hotel choices."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Visualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: Flight Price Distribution"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(flights['price'], bins=30)\n",
        "plt.title('Flight Price Distribution')\n",
        "plt.xlabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen to visualize the distribution of flight prices, helping identify the spread and common price ranges."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most flight prices are uniformly distributed between 400 and 1700. In real data, we might see peaks indicating common price points."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, understanding price distribution aids in setting competitive pricing strategies. No negative impact, as it informs pricing decisions."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: Distance vs Price"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x='distance', y='price', hue='flightType', data=flights)\n",
        "plt.title('Distance vs Flight Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen to explore the relationship between distance and price, with flightType as a hue to differentiate classes."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longer distances tend to have higher prices, with business class flights generally more expensive."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, this informs dynamic pricing models. No negative impact, as it aligns pricing with distance and class."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3: Hotel Price by Days"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='days', y='price', data=hotels)\n",
        "plt.title('Hotel Price by Stay Duration')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot shows the distribution of hotel prices across stay durations, highlighting medians and outliers."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longer stays may have varied price distributions, with some outliers for premium hotels."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, helps tailor hotel packages. No negative impact."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14: Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "# Drop non-numeric columns before calculating correlation\n",
        "numeric_flights = flights.select_dtypes(include=np.number)\n",
        "sns.heatmap(numeric_flights.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap for Flights')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap visualizes correlations between numerical features, aiding feature selection."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distance and price show a positive correlation, while time and price may also correlate."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15: Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(users[['age', 'gender']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot shows relationships between user features for classification tasks."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age distribution is uniform across genders."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Flight prices differ significantly by flightType.\n",
        "2. Hotel prices vary by stay duration.\n",
        "3. User age influences flight price selection."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Null: No difference in flight prices between economy and business.\n",
        "- Alternate: Flight prices differ significantly by flightType."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in flightType to see actual categories\n",
        "print(\"Unique flightType values:\", flights['flightType'].unique())\n",
        "print(\"Number of unique flightType:\", flights['flightType'].nunique())"
      ],
      "metadata": {
        "id": "U1XMHR6jnGQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy import stats\n",
        "economy_prices = flights[flights['flightType'] == 'economic']['price']\n",
        "business_prices = flights[flights['flightType'] == 'premium']['price']\n",
        "t_stat, p_val = stats.ttest_ind(economy_prices, business_prices)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test (independent samples)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test compares means of two groups (economy vs business prices), suitable for continuous data."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "flights.fillna({'price': flights['price'].mean()}, inplace=True)\n",
        "hotels.fillna({'price': hotels['price'].mean(), 'total': hotels['total'].mean()}, inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean imputation for numerical columns (price, total) to maintain data distribution. Suitable for small missing percentages."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "flights['price'] = flights['price'].clip(lower=flights['price'].quantile(0.05), upper=flights['price'].quantile(0.95))"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clipped prices at 5th and 95th percentiles to reduce extreme values' impact on models."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "cat_cols = ['from', 'to', 'flightType', 'agency']\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(flights[cat_cols]))\n",
        "encoded_cols.columns = encoder.get_feature_names_out(cat_cols)\n",
        "flights = pd.concat([flights.drop(cat_cols, axis=1), encoded_cols], axis=1)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding for categorical variables to convert them into numerical format for ML models."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['price', 'time', 'distance', 'day_of_week', 'month']\n",
        "flights[num_cols] = scaler.fit_transform(flights[num_cols])"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler to normalize numerical features, ensuring equal contribution to models."
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test\n",
        "X = flights.drop(['price', 'date', 'travelCode', 'userCode'], axis=1)\n",
        "y = flights['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "80/20 split to ensure sufficient training data while reserving enough for testing."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))  # Compute RMSE\n",
        "print(f\"Linear Regression RMSE: {rmse_lr}\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Linear Regression'], [rmse_lr])\n",
        "plt.title('RMSE for Linear Regression')\n",
        "plt.ylabel('RMSE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression assumes a linear relationship between features and price. RMSE indicates prediction error."
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))  # Compute RMSE\n",
        "print(f\"Random Forest RMSE: {rmse_rf}\")"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Linear Regression', 'Random Forest'], [rmse_lr, rmse_rf])\n",
        "plt.title('RMSE Comparison')\n",
        "plt.ylabel('RMSE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wNNTC-gMVX_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest handles non-linear relationships better, likely yielding lower RMSE."
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3: Gender Classification"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique gender values:\", users['gender'].unique())\n",
        "print(\"NaN count in gender:\", users['gender'].isna().sum())\n",
        "print(\"Value counts in gender:\\n\", users['gender'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "V2KC2jxQqNMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean gender column\n",
        "# Map 'male' and 'female', drop 'none'\n",
        "gender_mapping = {'male': 0, 'female': 1}\n",
        "users['gender_clean'] = users['gender'].map(gender_mapping)\n",
        "\n",
        "# Drop rows where gender is 'none' (unmapped values become NaN)\n",
        "users = users.dropna(subset=['gender_clean'])\n",
        "print(\"Rows after dropping unmapped genders:\", len(users))\n",
        "print(\"Unique values in gender_clean:\", users['gender_clean'].unique())\n",
        "\n",
        "# ML Model - 3 Implementation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_class = users[['age']]\n",
        "y_class = users['gender_clean']\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_c, y_train_c)\n",
        "y_pred_c = logreg.predict(X_test_c)\n",
        "acc = accuracy_score(y_test_c, y_pred_c)\n",
        "print(f\"Logistic Regression Accuracy: {acc}\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_test_c, y_pred_c), annot=True)\n",
        "plt.title('Confusion Matrix for Gender Classification')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression for binary classification of gender based on age."
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE for regression (flight price) to minimize prediction errors, impacting pricing accuracy. Accuracy for classification (gender) to ensure reliable demographic predictions."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest for flight price prediction due to lower RMSE, capturing non-linear relationships effectively."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8. Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process."
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "joblib.dump(rf, 'flight_price_model.pkl')"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check."
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data\n",
        "model = joblib.load('flight_price_model.pkl')\n",
        "sample = X_test.iloc[:5]\n",
        "predictions = model.predict(sample)\n",
        "print(f\"Sample predictions: {predictions}\")"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model = joblib.load('flight_price_model.pkl')\n",
        "print(\"Feature names used during training:\", model.feature_names_in_)"
      ],
      "metadata": {
        "id": "uFAeK2h9FlEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unscaled Prices\n"
      ],
      "metadata": {
        "id": "pW896lyZ4l8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load data (if not already loaded)\n",
        "flights = pd.read_csv('/content/drive/MyDrive/AlmaBetter DS/Capstone Project/travel_capstone/flights.csv')\n",
        "\n",
        "# Feature engineering (from your notebook)\n",
        "flights['date'] = pd.to_datetime(flights['date'])\n",
        "flights['day_of_week'] = flights['date'].dt.dayofweek\n",
        "flights['month'] = flights['date'].dt.month\n",
        "flights['price'].fillna(flights['price'].mean(), inplace=True)\n",
        "# Outlier clipping\n",
        "flights['price'] = flights['price'].clip(lower=flights['price'].quantile(0.05), upper=flights['price'].quantile(0.95))\n",
        "# Categorical encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "cat_cols = ['from', 'to', 'flightType', 'agency']\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(flights[cat_cols]))\n",
        "encoded_cols.columns = encoder.get_feature_names_out(cat_cols)\n",
        "flights = pd.concat([flights.drop(cat_cols, axis=1), encoded_cols], axis=1)\n",
        "joblib.dump(encoder, 'encoder.pkl')  # Save encoder for later use\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['price', 'time', 'distance', 'day_of_week', 'month']\n",
        "flights[num_cols] = scaler.fit_transform(flights[num_cols])\n",
        "joblib.dump(scaler, 'scaler.pkl')  # Save scaler\n",
        "print(\"Scaler saved as scaler.pkl\")\n",
        "\n",
        "# Data splitting\n",
        "X = flights.drop(['price', 'date', 'travelCode', 'userCode'], axis=1)\n",
        "y = flights['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "print(f\"Random Forest RMSE (scaled): {rmse_rf}\")\n",
        "joblib.dump(rf, 'flight_price_model.pkl')  # Save model\n",
        "print(\"Model saved as flight_price_model.pkl\")\n",
        "\n",
        "# Verify unscaled RMSE\n",
        "y_pred_unscaled = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred_rf.reshape(-1, 1), np.zeros((len(y_pred_rf), len(num_cols)-1))], axis=1)\n",
        ")[:, 0]\n",
        "y_test_unscaled = scaler.inverse_transform(\n",
        "    np.concatenate([y_test.values.reshape(-1, 1), np.zeros((len(y_test), len(num_cols)-1))], axis=1)\n",
        ")[:, 0]\n",
        "rmse_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))\n",
        "print(f\"Random Forest RMSE (unscaled): {rmse_unscaled}\")"
      ],
      "metadata": {
        "id": "7YwRR0zdykvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load('flight_price_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Ensure X_test is available (run data splitting if needed)\n",
        "sample = X_test.iloc[:5]\n",
        "predictions_scaled = model.predict(sample)  # Scaled predictions\n",
        "print(f\"Scaled predictions: {predictions_scaled}\")  # For debugging\n",
        "\n",
        "# Inverse-transform to get original price scale\n",
        "num_cols = ['price', 'time', 'distance', 'day_of_week', 'month']\n",
        "predictions_unscaled = scaler.inverse_transform(\n",
        "    np.concatenate([\n",
        "        predictions_scaled.reshape(-1, 1),  # Price predictions\n",
        "        np.zeros((len(predictions_scaled), len(num_cols)-1))  # Dummy values for other columns\n",
        "    ], axis=1)\n",
        ")[:, 0]  # Extract price column\n",
        "print(f\"Sample predictions (unscaled prices): {predictions_unscaled}\")"
      ],
      "metadata": {
        "id": "eEUlnEtzynhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLOps Implementation Instructions (External)"
      ],
      "metadata": {
        "id": "custom-mlops"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to Colab limitations, implemented\n",
        " the following externally:\n",
        "\n",
        "**Flask API (app.py)**:\n",
        "```python\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "app = Flask(__name__)\n",
        "model = joblib.load('flight_price_model.pkl')\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    df = pd.DataFrame([data])\n",
        "    # Preprocess df (encode, scale)\n",
        "    pred = model.predict(df)\n",
        "    return jsonify({'price': pred[0]})\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "```\n",
        "\n",
        "**Dockerfile**:\n",
        "```dockerfile\n",
        "FROM python:3.9-slim\n",
        "WORKDIR /app\n",
        "COPY . /app\n",
        "RUN pip install -r requirements.txt\n",
        "EXPOSE 5000\n",
        "CMD [\"python\", \"app.py\"]\n",
        "```\n",
        "\n",
        "**Kubernetes**: Create `deployment.yaml` and `service.yaml` for scaling.\n",
        "\n",
        "**Airflow DAG**: Write a DAG for data preprocessing and model retraining.\n",
        "\n",
        "**Jenkins**: Set up a Jenkinsfile for CI/CD.\n",
        "\n",
        "**MLFlow**: Log experiments using `mlflow.log_metric()`.\n",
        "\n",
        "**Streamlit App (app.py)**:\n",
        "```python\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from surprise import SVD, Dataset, Reader\n",
        "st.title('Hotel Recommendations')\n",
        "user_id = st.selectbox('Select User ID', range(100))\n",
        "# Load and predict recommendations\n",
        "st.write('Top Hotels:', ['HotelA', 'HotelB'])  # Example\n",
        "```\n",
        "\n",
        "Follow setup instructions in a local environment or cloud provider."
      ],
      "metadata": {
        "id": "mlops-instructions"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built regression (flight price), classification (gender), and recommendation (hotel) models with MLOps-ready instructions. Random Forest achieved the best RMSE for price prediction. The system enhances travel personalization and scalability."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}